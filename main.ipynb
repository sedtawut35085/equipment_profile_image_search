{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12a85f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/sedtawutchalothornnarumit/anaconda3/lib/python3.10/site-packages (4.57.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/sedtawutchalothornnarumit/anaconda3/lib/python3.10/site-packages (from transformers) (22.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/sedtawutchalothornnarumit/anaconda3/lib/python3.10/site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/sedtawutchalothornnarumit/anaconda3/lib/python3.10/site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/sedtawutchalothornnarumit/anaconda3/lib/python3.10/site-packages (from transformers) (1.26.2)\n",
      "Requirement already satisfied: requests in /Users/sedtawutchalothornnarumit/anaconda3/lib/python3.10/site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /Users/sedtawutchalothornnarumit/anaconda3/lib/python3.10/site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /Users/sedtawutchalothornnarumit/anaconda3/lib/python3.10/site-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/sedtawutchalothornnarumit/anaconda3/lib/python3.10/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/sedtawutchalothornnarumit/anaconda3/lib/python3.10/site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: filelock in /Users/sedtawutchalothornnarumit/anaconda3/lib/python3.10/site-packages (from transformers) (3.9.0)\n",
      "^C\n",
      "Requirement already satisfied: mysql-connector-python in /Users/sedtawutchalothornnarumit/anaconda3/lib/python3.10/site-packages (9.5.0)\n",
      "Requirement already satisfied: sentencepiece in /Users/sedtawutchalothornnarumit/anaconda3/lib/python3.10/site-packages (0.2.1)\n",
      "Requirement already satisfied: protobuf in /Users/sedtawutchalothornnarumit/anaconda3/lib/python3.10/site-packages (6.33.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade transformers\n",
    "!pip install mysql-connector-python\n",
    "!pip install sentencepiece\n",
    "!pip install protobuf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9aae572",
   "metadata": {},
   "source": [
    "SQL CONNECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cfd94465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Connected to TiDB successfully!\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "\n",
    "connection = mysql.connector.connect(\n",
    "  host = \"gateway01.ap-southeast-1.prod.aws.tidbcloud.com\",\n",
    "  port = 4000,\n",
    "  user = \"38pAbRBz5Urzj3r.root\",\n",
    "  password = \"dXIP2LwlYh0vkTdH\",\n",
    "  database = \"equipment_profile\",\n",
    "  ssl_ca = \"/etc/ssl/cert.pem\",\n",
    "  ssl_verify_cert = True,\n",
    "  ssl_verify_identity = True\n",
    ")\n",
    "if connection.is_connected():\n",
    "    print(\"‚úÖ Connected to TiDB successfully!\")\n",
    "else:\n",
    "    print(\"‚ùå Failed to connect to TiDB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98476d4",
   "metadata": {},
   "source": [
    "Create Vector from MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d1e92bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sedtawutchalothornnarumit/anaconda3/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoProcessor\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"google/siglip-base-patch16-224\")\n",
    "model = AutoModel.from_pretrained(\"google/siglip-base-patch16-224\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d07af7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b22f4c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting multi-class dataset processing...\n",
      "Found 7 classes: ['AI6', 'AI13', 'AI7', 'AI12', 'AI9', 'AI17', 'AI18']\n",
      "\n",
      "üìÅ Processing class: AI6\n",
      "Total images found: 104\n",
      "Training set: 83 images\n",
      "Validation set: 21 images\n",
      "‚úÖ AI6 training set processed: 83 embeddings\n",
      "‚úÖ AI6 validation set processed: 21 embeddings\n",
      "\n",
      "üìÅ Processing class: AI13\n",
      "Total images found: 102\n",
      "Training set: 81 images\n",
      "Validation set: 21 images\n",
      "‚úÖ AI13 training set processed: 81 embeddings\n",
      "‚úÖ AI13 validation set processed: 21 embeddings\n",
      "\n",
      "üìÅ Processing class: AI7\n",
      "Total images found: 112\n",
      "Training set: 89 images\n",
      "Validation set: 23 images\n",
      "‚úÖ AI7 training set processed: 89 embeddings\n",
      "‚úÖ AI7 validation set processed: 23 embeddings\n",
      "\n",
      "üìÅ Processing class: AI12\n",
      "Total images found: 92\n",
      "Training set: 73 images\n",
      "Validation set: 19 images\n",
      "‚úÖ AI12 training set processed: 73 embeddings\n",
      "‚úÖ AI12 validation set processed: 19 embeddings\n",
      "\n",
      "üìÅ Processing class: AI9\n",
      "Total images found: 163\n",
      "Training set: 130 images\n",
      "Validation set: 33 images\n",
      "‚úÖ AI9 training set processed: 130 embeddings\n",
      "‚úÖ AI9 validation set processed: 33 embeddings\n",
      "\n",
      "üìÅ Processing class: AI17\n",
      "Total images found: 103\n",
      "Training set: 82 images\n",
      "Validation set: 21 images\n",
      "‚úÖ AI17 training set processed: 82 embeddings\n",
      "‚úÖ AI17 validation set processed: 21 embeddings\n",
      "\n",
      "üìÅ Processing class: AI18\n",
      "Total images found: 127\n",
      "Training set: 101 images\n",
      "Validation set: 26 images\n",
      "‚úÖ AI18 training set processed: 101 embeddings\n",
      "‚úÖ AI18 validation set processed: 26 embeddings\n",
      "\n",
      "üéØ Overall Summary:\n",
      "Total classes processed: 7\n",
      "Total training embeddings: 639\n",
      "Total validation embeddings: 164\n",
      "\n",
      "üìä Training set class distribution:\n",
      "  AI6: 83 images\n",
      "  AI13: 81 images\n",
      "  AI7: 89 images\n",
      "  AI12: 73 images\n",
      "  AI9: 130 images\n",
      "  AI17: 82 images\n",
      "  AI18: 101 images\n",
      "\n",
      "üìä Validation set class distribution:\n",
      "  AI6: 21 images\n",
      "  AI13: 21 images\n",
      "  AI7: 23 images\n",
      "  AI12: 19 images\n",
      "  AI9: 33 images\n",
      "  AI17: 21 images\n",
      "  AI18: 26 images\n"
     ]
    }
   ],
   "source": [
    "def process_multi_class_dataset(dataset_path=\"dataset/\", test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Process multiple classes from different folders with train/validation split.\n",
    "    \"\"\"\n",
    "    all_train_embeddings = []\n",
    "    all_val_embeddings = []\n",
    "    \n",
    "    # Get all class folders\n",
    "    class_folders = [f for f in os.listdir(dataset_path) \n",
    "                    if os.path.isdir(os.path.join(dataset_path, f))]\n",
    "    \n",
    "    print(f\"Found {len(class_folders)} classes: {class_folders}\")\n",
    "    \n",
    "    for class_name in class_folders:\n",
    "        folder_path = os.path.join(dataset_path, class_name)\n",
    "        print(f\"\\nüìÅ Processing class: {class_name}\")\n",
    "        \n",
    "        # Get all image files for this class\n",
    "        image_files = []\n",
    "        for filename in os.listdir(folder_path):\n",
    "            if filename.lower().endswith((\".jpeg\", \".jpg\", \".png\", \".webp\")):\n",
    "                image_files.append(filename)\n",
    "        \n",
    "        if len(image_files) == 0:\n",
    "            print(f\"‚ö†Ô∏è No images found in {folder_path}\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"Total images found: {len(image_files)}\")\n",
    "        \n",
    "        # Split into train (80%) and validation (20%) for this class\n",
    "        train_files, val_files = train_test_split(\n",
    "            image_files, test_size=test_size, random_state=random_state\n",
    "        )\n",
    "        print(f\"Training set: {len(train_files)} images\")\n",
    "        print(f\"Validation set: {len(val_files)} images\")\n",
    "        \n",
    "        # Process training files for this class\n",
    "        class_train_embeddings = []\n",
    "        for filename in train_files:\n",
    "            path = os.path.join(folder_path, filename)\n",
    "            try:\n",
    "                image = Image.open(path)\n",
    "                \n",
    "                # Generate embedding for the image\n",
    "                inputs = processor(images=image, return_tensors=\"pt\")\n",
    "                with torch.no_grad():\n",
    "                    outputs = model.get_image_features(**inputs)\n",
    "                \n",
    "                embedding = outputs / outputs.norm(p=2, dim=-1, keepdim=True)  # normalize\n",
    "                \n",
    "                # Append embedding with label and file path\n",
    "                class_train_embeddings.append({\n",
    "                    \"embedding\": embedding.squeeze().tolist(),\n",
    "                    \"label\": class_name,\n",
    "                    \"file_path\": path\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error processing training file {filename}: {e}\")\n",
    "        \n",
    "        # Process validation files for this class\n",
    "        class_val_embeddings = []\n",
    "        for filename in val_files:\n",
    "            path = os.path.join(folder_path, filename)\n",
    "            try:\n",
    "                image = Image.open(path)\n",
    "                \n",
    "                # Generate embedding for the image\n",
    "                inputs = processor(images=image, return_tensors=\"pt\")\n",
    "                with torch.no_grad():\n",
    "                    outputs = model.get_image_features(**inputs)\n",
    "                \n",
    "                embedding = outputs / outputs.norm(p=2, dim=-1, keepdim=True)  # normalize\n",
    "                \n",
    "                # Append embedding with label and file path\n",
    "                class_val_embeddings.append({\n",
    "                    \"embedding\": embedding.squeeze().tolist(),\n",
    "                    \"label\": class_name,\n",
    "                    \"file_path\": path\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error processing validation file {filename}: {e}\")\n",
    "        \n",
    "        # Add to overall collections\n",
    "        all_train_embeddings.extend(class_train_embeddings)\n",
    "        all_val_embeddings.extend(class_val_embeddings)\n",
    "        \n",
    "        # Calculate summary statistics for this class\n",
    "        if class_train_embeddings:\n",
    "            class_train_summary = np.mean([item[\"embedding\"] for item in class_train_embeddings], axis=0)\n",
    "            print(f\"‚úÖ {class_name} training set processed: {len(class_train_embeddings)} embeddings\")\n",
    "        \n",
    "        if class_val_embeddings:\n",
    "            class_val_summary = np.mean([item[\"embedding\"] for item in class_val_embeddings], axis=0)\n",
    "            print(f\"‚úÖ {class_name} validation set processed: {len(class_val_embeddings)} embeddings\")\n",
    "    \n",
    "    print(f\"\\nüéØ Overall Summary:\")\n",
    "    print(f\"Total classes processed: {len(class_folders)}\")\n",
    "    print(f\"Total training embeddings: {len(all_train_embeddings)}\")\n",
    "    print(f\"Total validation embeddings: {len(all_val_embeddings)}\")\n",
    "    \n",
    "    return all_train_embeddings, all_val_embeddings\n",
    "\n",
    "# Process all classes\n",
    "print(\"üöÄ Starting multi-class dataset processing...\")\n",
    "train_embeddings, val_embeddings = process_multi_class_dataset(dataset_path=\"dataset/lamp\")\n",
    "\n",
    "# Show class distribution\n",
    "if train_embeddings:\n",
    "    train_class_counts = {}\n",
    "    for emb in train_embeddings:\n",
    "        label = emb[\"label\"]\n",
    "        train_class_counts[label] = train_class_counts.get(label, 0) + 1\n",
    "    \n",
    "    print(f\"\\nüìä Training set class distribution:\")\n",
    "    for class_name, count in train_class_counts.items():\n",
    "        print(f\"  {class_name}: {count} images\")\n",
    "\n",
    "if val_embeddings:\n",
    "    val_class_counts = {}\n",
    "    for emb in val_embeddings:\n",
    "        label = emb[\"label\"]\n",
    "        val_class_counts[label] = val_class_counts.get(label, 0) + 1\n",
    "    \n",
    "    print(f\"\\nüìä Validation set class distribution:\")\n",
    "    for class_name, count in val_class_counts.items():\n",
    "        print(f\"  {class_name}: {count} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a1ae86",
   "metadata": {},
   "source": [
    "Save on vector db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39f19c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saving training embeddings to database...\n",
      "Progress: 50/639 embeddings saved\n",
      "Progress: 100/639 embeddings saved\n",
      "Progress: 150/639 embeddings saved\n",
      "Progress: 200/639 embeddings saved\n",
      "Progress: 250/639 embeddings saved\n",
      "Progress: 300/639 embeddings saved\n",
      "Progress: 350/639 embeddings saved\n",
      "Progress: 400/639 embeddings saved\n",
      "Progress: 450/639 embeddings saved\n",
      "Progress: 500/639 embeddings saved\n",
      "Progress: 550/639 embeddings saved\n",
      "Progress: 600/639 embeddings saved\n",
      "\n",
      "‚úÖ Training embeddings saved to database successfully!\n",
      "Total training embeddings saved: 639\n",
      "\n",
      "üìä Training embeddings saved by class:\n",
      "  AI6: 83 embeddings\n",
      "  AI13: 81 embeddings\n",
      "  AI7: 89 embeddings\n",
      "  AI12: 73 embeddings\n",
      "  AI9: 130 embeddings\n",
      "  AI17: 82 embeddings\n",
      "  AI18: 101 embeddings\n",
      "\n",
      "Validation embeddings kept for evaluation: 164\n",
      "\n",
      "üìä Validation set ready for evaluation:\n",
      "Validation embeddings available in 'val_embeddings' variable\n",
      "\n",
      "üìä Validation embeddings by class:\n",
      "  AI6: 21 embeddings\n",
      "  AI13: 21 embeddings\n",
      "  AI7: 23 embeddings\n",
      "  AI12: 19 embeddings\n",
      "  AI9: 33 embeddings\n",
      "  AI17: 21 embeddings\n",
      "  AI18: 26 embeddings\n"
     ]
    }
   ],
   "source": [
    "# Create cursor for database operations\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# Clear previous data (optional - remove this if you want to keep existing data)\n",
    "# cursor.execute(\"DELETE FROM equipment_embeddings\")\n",
    "# print(\"üóëÔ∏è Cleared existing embeddings from database\")\n",
    "\n",
    "# Only save training embeddings to the database\n",
    "train_count_by_class = {}\n",
    "total_train_count = 0\n",
    "\n",
    "print(\"üíæ Saving training embeddings to database...\")\n",
    "\n",
    "for idx, embedding in enumerate(train_embeddings):\n",
    "    # Extract the embedding, label, and file path\n",
    "    embedding_list = embedding[\"embedding\"]\n",
    "    label = embedding[\"label\"]\n",
    "    file_path = embedding[\"file_path\"]\n",
    "\n",
    "    # Insert the embedding into the database\n",
    "    insert_query = \"\"\"\n",
    "    INSERT INTO equipment_embeddings (class_name, image_embedding, path) \n",
    "    VALUES (%s, %s, %s)\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert embedding to JSON string\n",
    "    embedding_json = json.dumps(embedding_list)\n",
    "\n",
    "    # Execute the insert\n",
    "    cursor.execute(insert_query, (label, embedding_json, file_path))\n",
    "    \n",
    "    # Count by class\n",
    "    train_count_by_class[label] = train_count_by_class.get(label, 0) + 1\n",
    "    total_train_count += 1\n",
    "    \n",
    "    # Show progress every 50 embeddings\n",
    "    if (idx + 1) % 50 == 0:\n",
    "        print(f\"Progress: {idx + 1}/{len(train_embeddings)} embeddings saved\")\n",
    "\n",
    "# Commit the transaction\n",
    "connection.commit()\n",
    "\n",
    "print(f\"\\n‚úÖ Training embeddings saved to database successfully!\")\n",
    "print(f\"Total training embeddings saved: {total_train_count}\")\n",
    "\n",
    "print(f\"\\nüìä Training embeddings saved by class:\")\n",
    "for class_name, count in train_count_by_class.items():\n",
    "    print(f\"  {class_name}: {count} embeddings\")\n",
    "\n",
    "print(f\"\\nValidation embeddings kept for evaluation: {len(val_embeddings)}\")\n",
    "\n",
    "# Close cursor\n",
    "cursor.close()\n",
    "\n",
    "# Keep validation embeddings in memory for evaluation\n",
    "print(f\"\\nüìä Validation set ready for evaluation:\")\n",
    "print(f\"Validation embeddings available in 'val_embeddings' variable\")\n",
    "\n",
    "# Show validation class distribution\n",
    "val_count_by_class = {}\n",
    "for emb in val_embeddings:\n",
    "    label = emb[\"label\"]\n",
    "    val_count_by_class[label] = val_count_by_class.get(label, 0) + 1\n",
    "\n",
    "print(f\"\\nüìä Validation embeddings by class:\")\n",
    "for class_name, count in val_count_by_class.items():\n",
    "    print(f\"  {class_name}: {count} embeddings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b84084",
   "metadata": {},
   "source": [
    "Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9706713",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_on_validation(val_embeddings, connection, top_k=5):\n",
    "    \"\"\"\n",
    "    Evaluate the model using validation embeddings.\n",
    "    This function tests how well the model can retrieve similar images from the database\n",
    "    using validation set images as queries.\n",
    "    \"\"\"\n",
    "    correct_predictions = 0\n",
    "    total_predictions = len(val_embeddings)\n",
    "    \n",
    "    print(f\"üîç Evaluating model on {total_predictions} validation images...\")\n",
    "    \n",
    "    for i, val_embedding in enumerate(val_embeddings):\n",
    "        # Use the validation embedding as a query\n",
    "        query_embedding = val_embedding[\"embedding\"]\n",
    "        true_label = val_embedding[\"label\"]\n",
    "        \n",
    "        # Search in the database (which only contains training data)\n",
    "        cur = connection.cursor()\n",
    "        sql = \"\"\"\n",
    "        SELECT class_name, path, \n",
    "               vec_cosine_distance(image_embedding, %s) AS distance\n",
    "        FROM equipment_embeddings\n",
    "        ORDER BY distance ASC\n",
    "        LIMIT %s;\n",
    "        \"\"\"\n",
    "        cur.execute(sql, (json.dumps(query_embedding), top_k))\n",
    "        results = cur.fetchall()\n",
    "        cur.close()\n",
    "        \n",
    "        # Check if the top result matches the true label\n",
    "        if results and results[0][0] == true_label:\n",
    "            correct_predictions += 1\n",
    "        \n",
    "        # Print progress every 10 images\n",
    "        if (i + 1) % 10 == 0:\n",
    "            print(f\"Progress: {i + 1}/{total_predictions}\")\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = correct_predictions / total_predictions * 100\n",
    "    \n",
    "    print(f\"\\nüìà Evaluation Results:\")\n",
    "    print(f\"Correct predictions: {correct_predictions}/{total_predictions}\")\n",
    "    print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "    \n",
    "    return accuracy, correct_predictions, total_predictions\n",
    "\n",
    "def evaluate_single_validation_image(val_embedding, connection, top_k=5, show_results=True):\n",
    "    \"\"\"\n",
    "    Evaluate a single validation image and optionally show the top-k results.\n",
    "    \"\"\"\n",
    "    query_embedding = val_embedding[\"embedding\"]\n",
    "    true_label = val_embedding[\"label\"]\n",
    "    true_path = val_embedding[\"file_path\"]\n",
    "    \n",
    "    # Search in the database\n",
    "    cur = connection.cursor()\n",
    "    sql = \"\"\"\n",
    "    SELECT class_name, path, \n",
    "           vec_cosine_distance(image_embedding, %s) AS distance\n",
    "    FROM equipment_embeddings\n",
    "    ORDER BY distance ASC\n",
    "    LIMIT %s;\n",
    "    \"\"\"\n",
    "    cur.execute(sql, (json.dumps(query_embedding), top_k))\n",
    "    results = cur.fetchall()\n",
    "    cur.close()\n",
    "    \n",
    "    if show_results:\n",
    "        print(f\"üîç Query image: {true_path} (True label: {true_label})\")\n",
    "        print(f\"Top {top_k} similar images from training set:\")\n",
    "        for i, (class_name, path, distance) in enumerate(results, 1):\n",
    "            print(f\"{i}. {class_name} - {path} (Distance: {distance:.4f})\")\n",
    "        \n",
    "        # Check if prediction is correct\n",
    "        if results and results[0][0] == true_label:\n",
    "            print(\"‚úÖ Correct prediction!\")\n",
    "        else:\n",
    "            print(\"‚ùå Incorrect prediction!\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7923f42f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'embedding': [0.00999145582318306,\n",
       "  0.005636109039187431,\n",
       "  -0.015741651877760887,\n",
       "  -0.012561262585222721,\n",
       "  0.013491141609847546,\n",
       "  -0.0045211235992610455,\n",
       "  -0.04264356568455696,\n",
       "  0.011754568666219711,\n",
       "  0.009394015185534954,\n",
       "  -0.008598537184298038,\n",
       "  -0.034180108457803726,\n",
       "  -0.022763526067137718,\n",
       "  0.0003152881981804967,\n",
       "  -0.04315571114420891,\n",
       "  0.04794676601886749,\n",
       "  0.018598522990942,\n",
       "  0.0004804178315680474,\n",
       "  0.018340732902288437,\n",
       "  -0.010301368311047554,\n",
       "  -0.02002836763858795,\n",
       "  -0.00132858008146286,\n",
       "  0.004363843705505133,\n",
       "  -0.017565108835697174,\n",
       "  -0.01152846310287714,\n",
       "  0.011091613210737705,\n",
       "  0.004461731296032667,\n",
       "  -0.002792836632579565,\n",
       "  -0.0027391051407903433,\n",
       "  -0.02408241108059883,\n",
       "  -0.005921161733567715,\n",
       "  -0.020677225664258003,\n",
       "  0.0019129830179736018,\n",
       "  -0.009094078093767166,\n",
       "  -0.022882815450429916,\n",
       "  0.0005069212638773024,\n",
       "  0.005463782232254744,\n",
       "  0.012885595671832561,\n",
       "  0.0014607246266677976,\n",
       "  -0.016165511682629585,\n",
       "  0.04157884418964386,\n",
       "  0.027927283197641373,\n",
       "  0.025437356904149055,\n",
       "  0.026398124173283577,\n",
       "  -0.027270419523119926,\n",
       "  -0.003707590512931347,\n",
       "  -0.002994535258039832,\n",
       "  -0.00043192310840822756,\n",
       "  -0.02686505764722824,\n",
       "  -0.0003106904332526028,\n",
       "  -0.003925910219550133,\n",
       "  -0.011640436016023159,\n",
       "  -0.00948834978044033,\n",
       "  -0.004561219364404678,\n",
       "  0.0015818270621821284,\n",
       "  0.10549391061067581,\n",
       "  -0.061337169259786606,\n",
       "  0.023391112685203552,\n",
       "  0.019919520244002342,\n",
       "  -0.008870061486959457,\n",
       "  -0.040471240878105164,\n",
       "  0.008336960338056087,\n",
       "  0.029267940670251846,\n",
       "  0.00569260073825717,\n",
       "  0.00772888446226716,\n",
       "  0.02337834984064102,\n",
       "  -0.0062581198289990425,\n",
       "  0.02939365804195404,\n",
       "  0.03021804429590702,\n",
       "  0.0045846374705433846,\n",
       "  0.008534228429198265,\n",
       "  0.023994142189621925,\n",
       "  0.014908880926668644,\n",
       "  0.005240964237600565,\n",
       "  -0.009933819063007832,\n",
       "  -0.021742329001426697,\n",
       "  0.05859517678618431,\n",
       "  9.868398774415255e-05,\n",
       "  0.013399309478700161,\n",
       "  0.4698440134525299,\n",
       "  0.02321353182196617,\n",
       "  0.008693293668329716,\n",
       "  -0.019741496071219444,\n",
       "  0.009321631863713264,\n",
       "  0.012744230218231678,\n",
       "  0.0013771329540759325,\n",
       "  -0.10098977386951447,\n",
       "  0.029177602380514145,\n",
       "  0.011539260856807232,\n",
       "  0.012661943212151527,\n",
       "  0.012819581665098667,\n",
       "  0.014856343157589436,\n",
       "  0.019436515867710114,\n",
       "  -0.010817283764481544,\n",
       "  0.010151609778404236,\n",
       "  0.0645173192024231,\n",
       "  -0.022712163627147675,\n",
       "  -0.028208425268530846,\n",
       "  -0.02668161131441593,\n",
       "  0.017695974558591843,\n",
       "  0.014419971033930779,\n",
       "  0.003252537688240409,\n",
       "  0.003973605576902628,\n",
       "  0.003188914153724909,\n",
       "  -0.022838376462459564,\n",
       "  0.01347306091338396,\n",
       "  -0.036636415868997574,\n",
       "  0.026110317558050156,\n",
       "  -0.027287550270557404,\n",
       "  -0.005129231605678797,\n",
       "  0.011753813363611698,\n",
       "  -0.0015880727441981435,\n",
       "  -0.03228020295500755,\n",
       "  0.0024800822138786316,\n",
       "  0.012187139131128788,\n",
       "  0.014152124524116516,\n",
       "  0.03323587402701378,\n",
       "  -0.033821504563093185,\n",
       "  -0.012837973423302174,\n",
       "  0.017104370519518852,\n",
       "  0.0033605473581701517,\n",
       "  0.007480566389858723,\n",
       "  -0.0049790325574576855,\n",
       "  0.027808358892798424,\n",
       "  0.007480435539036989,\n",
       "  -0.03539764881134033,\n",
       "  0.017555659636855125,\n",
       "  0.025410830974578857,\n",
       "  -0.012777144089341164,\n",
       "  0.0763852596282959,\n",
       "  -0.00914578977972269,\n",
       "  0.0072174472734332085,\n",
       "  0.016330519691109657,\n",
       "  -0.025562023743987083,\n",
       "  -0.004202188458293676,\n",
       "  -0.011800228618085384,\n",
       "  -0.012652814388275146,\n",
       "  0.01364822592586279,\n",
       "  -0.0012878235429525375,\n",
       "  0.11041738837957382,\n",
       "  -0.005335637833923101,\n",
       "  -0.01228917483240366,\n",
       "  -0.01790473610162735,\n",
       "  -0.01741788536310196,\n",
       "  -0.008914726786315441,\n",
       "  0.01944301836192608,\n",
       "  0.01619478315114975,\n",
       "  0.011194749735295773,\n",
       "  -0.01197346206754446,\n",
       "  0.017035333439707756,\n",
       "  0.005474818404763937,\n",
       "  -0.01075793243944645,\n",
       "  0.005527031607925892,\n",
       "  -0.003312568413093686,\n",
       "  0.13631170988082886,\n",
       "  -0.022907953709363937,\n",
       "  0.015439800918102264,\n",
       "  0.008428474888205528,\n",
       "  0.060031116008758545,\n",
       "  -0.003297274699434638,\n",
       "  0.02198617532849312,\n",
       "  -0.010623201727867126,\n",
       "  0.0002926338347606361,\n",
       "  0.024994982406497,\n",
       "  0.0043977294117212296,\n",
       "  -0.021624194458127022,\n",
       "  -0.012510343454778194,\n",
       "  -0.01607523299753666,\n",
       "  -0.007510094437748194,\n",
       "  0.01946253702044487,\n",
       "  -0.0074809035286307335,\n",
       "  0.002251438796520233,\n",
       "  0.010721388272941113,\n",
       "  0.06151125580072403,\n",
       "  -0.00026586485910229385,\n",
       "  -0.06710038334131241,\n",
       "  0.014518693089485168,\n",
       "  0.020171143114566803,\n",
       "  -0.004228337202221155,\n",
       "  -0.011472927406430244,\n",
       "  -0.007644138298928738,\n",
       "  -0.04404519498348236,\n",
       "  0.10484551638364792,\n",
       "  0.012237956747412682,\n",
       "  -0.024736568331718445,\n",
       "  0.02518436312675476,\n",
       "  0.04084417223930359,\n",
       "  -0.0076989177614450455,\n",
       "  0.028071023523807526,\n",
       "  -0.0012800496770069003,\n",
       "  0.03257701173424721,\n",
       "  0.02496051788330078,\n",
       "  0.010349318385124207,\n",
       "  0.004741818178445101,\n",
       "  0.03900706395506859,\n",
       "  0.004572124686092138,\n",
       "  -0.008859955705702305,\n",
       "  -0.07114129513502121,\n",
       "  0.027241865172982216,\n",
       "  0.002957557560876012,\n",
       "  -0.0013745741453021765,\n",
       "  0.00809583067893982,\n",
       "  0.01775701344013214,\n",
       "  -0.011404115706682205,\n",
       "  0.005399472080171108,\n",
       "  0.004283972550183535,\n",
       "  -0.007454847451299429,\n",
       "  -0.0012482135789468884,\n",
       "  -0.03682724013924599,\n",
       "  -0.059466537088155746,\n",
       "  0.014589579775929451,\n",
       "  -0.017592530697584152,\n",
       "  0.030443433672189713,\n",
       "  -0.0011057006195187569,\n",
       "  -0.031989697366952896,\n",
       "  0.011781352572143078,\n",
       "  0.006651689764112234,\n",
       "  0.011484852060675621,\n",
       "  -0.011029226705431938,\n",
       "  0.0011362850200384855,\n",
       "  -0.05168736353516579,\n",
       "  0.006677041295915842,\n",
       "  -0.006091981194913387,\n",
       "  0.019138645380735397,\n",
       "  -0.006191163789480925,\n",
       "  -0.0012742870021611452,\n",
       "  0.009034084156155586,\n",
       "  0.0213908888399601,\n",
       "  0.016219930723309517,\n",
       "  -0.03491903841495514,\n",
       "  -0.01877759024500847,\n",
       "  0.019422005861997604,\n",
       "  0.027495982125401497,\n",
       "  -0.005991565063595772,\n",
       "  -0.0012500331504270434,\n",
       "  -0.028046762570738792,\n",
       "  0.01095635537058115,\n",
       "  0.025427307933568954,\n",
       "  0.01187281683087349,\n",
       "  0.01923990622162819,\n",
       "  0.01331328134983778,\n",
       "  -0.008931610733270645,\n",
       "  0.029463108628988266,\n",
       "  0.007951329462230206,\n",
       "  -0.02162778377532959,\n",
       "  0.025893189013004303,\n",
       "  -0.02260902151465416,\n",
       "  0.01136987004429102,\n",
       "  0.03171859309077263,\n",
       "  -0.051334645599126816,\n",
       "  -0.013733978383243084,\n",
       "  -0.017877256497740746,\n",
       "  0.009488829411566257,\n",
       "  0.02954612299799919,\n",
       "  0.025031257420778275,\n",
       "  0.017209751531481743,\n",
       "  0.015123341232538223,\n",
       "  0.017122706398367882,\n",
       "  0.03746038302779198,\n",
       "  0.002471311017870903,\n",
       "  0.044488463550806046,\n",
       "  -0.02204541116952896,\n",
       "  -0.009415104985237122,\n",
       "  0.008403272368013859,\n",
       "  -0.008635994978249073,\n",
       "  -0.0031029891688376665,\n",
       "  -0.01724662259221077,\n",
       "  0.018434753641486168,\n",
       "  0.032391760498285294,\n",
       "  0.011539412662386894,\n",
       "  0.014412106946110725,\n",
       "  -0.054526522755622864,\n",
       "  -0.012022372335195541,\n",
       "  0.006567459087818861,\n",
       "  -0.012362762354314327,\n",
       "  -0.017796987667679787,\n",
       "  0.019458847120404243,\n",
       "  -0.04707535356283188,\n",
       "  0.01788976415991783,\n",
       "  0.014474723488092422,\n",
       "  -0.014623643830418587,\n",
       "  -0.0399509072303772,\n",
       "  0.011097924783825874,\n",
       "  -0.026739662513136864,\n",
       "  0.01108552422374487,\n",
       "  -0.03800872713327408,\n",
       "  -0.004516628570854664,\n",
       "  -0.008327106945216656,\n",
       "  0.010647783987224102,\n",
       "  -0.002094162628054619,\n",
       "  0.016248617321252823,\n",
       "  0.01470180880278349,\n",
       "  0.010574021376669407,\n",
       "  -0.008478338830173016,\n",
       "  0.006174221634864807,\n",
       "  -0.002760730218142271,\n",
       "  -0.0017696063732728362,\n",
       "  0.02987663634121418,\n",
       "  0.001499149133451283,\n",
       "  0.00030892505310475826,\n",
       "  0.0761161670088768,\n",
       "  0.015460535883903503,\n",
       "  0.34074175357818604,\n",
       "  -0.010506639257073402,\n",
       "  0.019165804609656334,\n",
       "  0.018042750656604767,\n",
       "  0.0007981779635883868,\n",
       "  0.0007734349928796291,\n",
       "  -0.019164618104696274,\n",
       "  -0.007612651214003563,\n",
       "  0.0013429275713860989,\n",
       "  -0.046259358525276184,\n",
       "  -0.008119132369756699,\n",
       "  0.00031597676570527256,\n",
       "  0.003438356099650264,\n",
       "  -0.015864074230194092,\n",
       "  0.032337553799152374,\n",
       "  -0.01038516778498888,\n",
       "  0.00284279091283679,\n",
       "  0.008065209724009037,\n",
       "  0.0047881449572741985,\n",
       "  0.006729748100042343,\n",
       "  -0.0066889263689517975,\n",
       "  -0.018810875713825226,\n",
       "  0.0016654684441164136,\n",
       "  0.10057705640792847,\n",
       "  0.014235776849091053,\n",
       "  0.02209603600203991,\n",
       "  0.006027898285537958,\n",
       "  0.004951957147568464,\n",
       "  -0.016730327159166336,\n",
       "  -0.015959301963448524,\n",
       "  0.17142848670482635,\n",
       "  -0.015378592535853386,\n",
       "  0.02905401587486267,\n",
       "  -0.011063731275498867,\n",
       "  -0.023340819403529167,\n",
       "  0.034371327608823776,\n",
       "  0.018124159425497055,\n",
       "  0.011761840432882309,\n",
       "  -0.013578072190284729,\n",
       "  0.009596254676580429,\n",
       "  0.004857873078435659,\n",
       "  -0.0008056354708969593,\n",
       "  -0.011176461353898048,\n",
       "  -0.02690911293029785,\n",
       "  -0.02455686777830124,\n",
       "  -0.009654225781559944,\n",
       "  0.023783842101693153,\n",
       "  -0.001306555001065135,\n",
       "  -0.029835082590579987,\n",
       "  -0.008792360313236713,\n",
       "  -0.017586510628461838,\n",
       "  0.025383470579981804,\n",
       "  0.033063601702451706,\n",
       "  0.026497652754187584,\n",
       "  0.005233706906437874,\n",
       "  -0.04076525568962097,\n",
       "  -0.01648545451462269,\n",
       "  -0.03170342743396759,\n",
       "  -0.00451327208429575,\n",
       "  0.032210562378168106,\n",
       "  0.008212518878281116,\n",
       "  -0.025270674377679825,\n",
       "  -0.01903740130364895,\n",
       "  0.008260846138000488,\n",
       "  -0.0011254230048507452,\n",
       "  0.00662875035777688,\n",
       "  -0.01154468022286892,\n",
       "  -0.03177624195814133,\n",
       "  -0.0016323461895808578,\n",
       "  -0.027419697493314743,\n",
       "  -0.03192756697535515,\n",
       "  0.0075507862493395805,\n",
       "  0.004695648327469826,\n",
       "  0.012484278529882431,\n",
       "  0.002214918378740549,\n",
       "  -0.012988975271582603,\n",
       "  -0.007814456708729267,\n",
       "  -0.04894416779279709,\n",
       "  -0.02750461921095848,\n",
       "  -0.03745635226368904,\n",
       "  -0.018069269135594368,\n",
       "  -0.007784627843648195,\n",
       "  -0.004701891914010048,\n",
       "  -0.003203090513125062,\n",
       "  0.03238779678940773,\n",
       "  0.004642427433282137,\n",
       "  -0.006360347848385572,\n",
       "  0.01616371050477028,\n",
       "  -0.024294376373291016,\n",
       "  0.01982017047703266,\n",
       "  0.01524709165096283,\n",
       "  0.015395820140838623,\n",
       "  -0.013740499503910542,\n",
       "  -0.019406337291002274,\n",
       "  0.007040744181722403,\n",
       "  0.05062674731016159,\n",
       "  -0.007735845632851124,\n",
       "  -0.03942565992474556,\n",
       "  0.019089700654149055,\n",
       "  -0.010820002295076847,\n",
       "  -0.01930711604654789,\n",
       "  -0.009546774439513683,\n",
       "  -0.03196175396442413,\n",
       "  0.047977808862924576,\n",
       "  -0.011096346192061901,\n",
       "  -0.01274628471583128,\n",
       "  0.004010241013020277,\n",
       "  0.018650630488991737,\n",
       "  -0.0007104523247107863,\n",
       "  -0.04111151397228241,\n",
       "  0.022750865668058395,\n",
       "  -0.0012329701567068696,\n",
       "  -0.006474083289504051,\n",
       "  -0.0005780471838079393,\n",
       "  0.002458584262058139,\n",
       "  -0.01569424569606781,\n",
       "  -0.01637732796370983,\n",
       "  -0.012173424474895,\n",
       "  0.004501840565353632,\n",
       "  0.009011726826429367,\n",
       "  -0.02360093593597412,\n",
       "  -0.003749231342226267,\n",
       "  0.011958543211221695,\n",
       "  0.025865627452731133,\n",
       "  -0.004017746541649103,\n",
       "  -0.0367354191839695,\n",
       "  -0.03453385457396507,\n",
       "  0.014305155724287033,\n",
       "  0.011522684246301651,\n",
       "  -0.016787538304924965,\n",
       "  0.02495700679719448,\n",
       "  0.016939982771873474,\n",
       "  -0.010198717936873436,\n",
       "  -0.002706296509131789,\n",
       "  0.02362907864153385,\n",
       "  0.01656734012067318,\n",
       "  -0.03387963026762009,\n",
       "  0.018432172015309334,\n",
       "  -0.025186019018292427,\n",
       "  0.01140971202403307,\n",
       "  -8.681314648129046e-05,\n",
       "  0.005386148579418659,\n",
       "  -0.08909334987401962,\n",
       "  0.02888430655002594,\n",
       "  -0.01441920269280672,\n",
       "  0.005974476225674152,\n",
       "  -0.012161333113908768,\n",
       "  0.03809879720211029,\n",
       "  0.013206546194851398,\n",
       "  -0.005754894111305475,\n",
       "  -0.014744835905730724,\n",
       "  -0.019582992419600487,\n",
       "  -0.0027199438773095608,\n",
       "  0.009664504788815975,\n",
       "  -0.005057858303189278,\n",
       "  -0.006141914986073971,\n",
       "  0.012166510336101055,\n",
       "  -0.008569897152483463,\n",
       "  -0.009188422001898289,\n",
       "  0.0029984740540385246,\n",
       "  0.015093660913407803,\n",
       "  -0.010755143128335476,\n",
       "  -0.002641832921653986,\n",
       "  0.007950322702527046,\n",
       "  -0.013831756077706814,\n",
       "  0.028551282361149788,\n",
       "  -0.012744754552841187,\n",
       "  -0.04284588620066643,\n",
       "  0.010547003708779812,\n",
       "  -0.006357585079967976,\n",
       "  -0.013321870937943459,\n",
       "  -0.0067222388461232185,\n",
       "  -0.0015149046666920185,\n",
       "  0.01734308712184429,\n",
       "  0.012645488604903221,\n",
       "  0.006909335497766733,\n",
       "  -0.02711556665599346,\n",
       "  0.000787065364420414,\n",
       "  -0.02077922783792019,\n",
       "  -0.01731494627892971,\n",
       "  -0.019323376938700676,\n",
       "  -0.0021325715351849794,\n",
       "  0.007253848947584629,\n",
       "  -0.12198901176452637,\n",
       "  -0.013009593822062016,\n",
       "  0.019364528357982635,\n",
       "  -0.014194067567586899,\n",
       "  0.01789953000843525,\n",
       "  -0.008983277715742588,\n",
       "  0.00018127357179764658,\n",
       "  0.000643113802652806,\n",
       "  0.004946591332554817,\n",
       "  -0.007814226672053337,\n",
       "  0.014888773672282696,\n",
       "  -0.028577683493494987,\n",
       "  -0.03570107743144035,\n",
       "  -0.014447027817368507,\n",
       "  0.01558851171284914,\n",
       "  0.03598148748278618,\n",
       "  0.0038990757893770933,\n",
       "  0.005680084228515625,\n",
       "  0.015732672065496445,\n",
       "  0.015284311957657337,\n",
       "  -0.019084731116890907,\n",
       "  0.0014108676696196198,\n",
       "  -0.005767163820564747,\n",
       "  0.0004935658071190119,\n",
       "  -0.001903755241073668,\n",
       "  -0.020467203110456467,\n",
       "  0.056720104068517685,\n",
       "  -0.0018148533999919891,\n",
       "  -0.012071161530911922,\n",
       "  -0.011026034131646156,\n",
       "  0.012472680769860744,\n",
       "  0.007236403878778219,\n",
       "  0.0049031260423362255,\n",
       "  0.0013806404313072562,\n",
       "  0.015046349726617336,\n",
       "  -0.04023684561252594,\n",
       "  -0.013169907033443451,\n",
       "  -0.010976775549352169,\n",
       "  0.022696271538734436,\n",
       "  -0.03640955314040184,\n",
       "  0.020060451701283455,\n",
       "  0.0071764132007956505,\n",
       "  0.017652051523327827,\n",
       "  -0.006490197032690048,\n",
       "  0.020111622288823128,\n",
       "  0.0036106747575104237,\n",
       "  0.0007775570848025382,\n",
       "  0.008678600192070007,\n",
       "  -0.004894842393696308,\n",
       "  -0.03361954167485237,\n",
       "  -0.01837259531021118,\n",
       "  -0.05453581362962723,\n",
       "  0.015552166849374771,\n",
       "  0.009332286193966866,\n",
       "  -0.0021004173904657364,\n",
       "  -0.03599299490451813,\n",
       "  0.02752089686691761,\n",
       "  -0.01047009788453579,\n",
       "  0.021545536816120148,\n",
       "  -0.023446831852197647,\n",
       "  0.03489278629422188,\n",
       "  0.002526750322431326,\n",
       "  -0.01743689738214016,\n",
       "  0.004408867564052343,\n",
       "  -0.010971284471452236,\n",
       "  0.010778135620057583,\n",
       "  -0.0160911213606596,\n",
       "  -0.012504356913268566,\n",
       "  0.02499188855290413,\n",
       "  0.02489224076271057,\n",
       "  0.04437604174017906,\n",
       "  0.012961992993950844,\n",
       "  0.03510964289307594,\n",
       "  0.020711824297904968,\n",
       "  0.04014475271105766,\n",
       "  -0.004865657538175583,\n",
       "  -0.015513533726334572,\n",
       "  0.0053639719262719154,\n",
       "  -0.01901160553097725,\n",
       "  0.0032427178230136633,\n",
       "  0.02489304356276989,\n",
       "  -0.004254085011780262,\n",
       "  -0.020424168556928635,\n",
       "  -0.004466250538825989,\n",
       "  -0.007858166471123695,\n",
       "  -0.007552764378488064,\n",
       "  0.01961868442595005,\n",
       "  -0.049502164125442505,\n",
       "  -0.0362933911383152,\n",
       "  0.00995473749935627,\n",
       "  -0.024287715554237366,\n",
       "  0.025430887937545776,\n",
       "  -0.01923407055437565,\n",
       "  0.009549930691719055,\n",
       "  0.00629250705242157,\n",
       "  -0.015164406970143318,\n",
       "  0.015934396535158157,\n",
       "  -0.004664084408432245,\n",
       "  -0.022493800148367882,\n",
       "  -0.014647436328232288,\n",
       "  -0.004935535602271557,\n",
       "  -0.02291504479944706,\n",
       "  -0.02511344663798809,\n",
       "  0.009389807470142841,\n",
       "  0.0006815096130594611,\n",
       "  -0.008829131722450256,\n",
       "  0.006623450201004744,\n",
       "  0.012827828526496887,\n",
       "  0.010896923020482063,\n",
       "  -0.007610929664224386,\n",
       "  0.006105080712586641,\n",
       "  0.019221607595682144,\n",
       "  0.02573898620903492,\n",
       "  -0.022561755031347275,\n",
       "  0.0068112630397081375,\n",
       "  0.016332237049937248,\n",
       "  -0.016233175992965698,\n",
       "  0.029767192900180817,\n",
       "  -0.014465526677668095,\n",
       "  -0.051107924431562424,\n",
       "  -0.014482054859399796,\n",
       "  -0.0184601079672575,\n",
       "  0.003476077690720558,\n",
       "  -0.0014724942157045007,\n",
       "  -0.011035137809813023,\n",
       "  0.02203006111085415,\n",
       "  0.004408218432217836,\n",
       "  0.016263462603092194,\n",
       "  -0.004649338312447071,\n",
       "  -0.024895137175917625,\n",
       "  0.007421680260449648,\n",
       "  -0.00011970734340138733,\n",
       "  0.03196553885936737,\n",
       "  -0.01477032620459795,\n",
       "  -0.00791666004806757,\n",
       "  0.015082248486578465,\n",
       "  0.026463918387889862,\n",
       "  0.011015643365681171,\n",
       "  -0.01656976528465748,\n",
       "  0.0057974932715296745,\n",
       "  0.02210262045264244,\n",
       "  0.015286044217646122,\n",
       "  -0.015380504541099072,\n",
       "  0.009139006026089191,\n",
       "  -0.03592509403824806,\n",
       "  -0.003135190112516284,\n",
       "  0.013740768656134605,\n",
       "  0.001215834286995232,\n",
       "  -0.005233579780906439,\n",
       "  -0.003620933508500457,\n",
       "  0.029554272070527077,\n",
       "  -0.016917003318667412,\n",
       "  0.028688481077551842,\n",
       "  -0.008524061180651188,\n",
       "  0.025873050093650818,\n",
       "  -0.0050850119441747665,\n",
       "  -0.0038921386003494263,\n",
       "  -0.014025130309164524,\n",
       "  0.00935650710016489,\n",
       "  0.018480176106095314,\n",
       "  0.01998296193778515,\n",
       "  0.027373097836971283,\n",
       "  -0.11249940097332001,\n",
       "  -0.0377814806997776,\n",
       "  -0.006686454173177481,\n",
       "  -0.004279191140085459,\n",
       "  0.11940076947212219,\n",
       "  -0.014116213656961918,\n",
       "  -0.01690172217786312,\n",
       "  -0.032625604420900345,\n",
       "  -0.0031967118848115206,\n",
       "  0.03169193118810654,\n",
       "  0.01583348959684372,\n",
       "  -0.07273467630147934,\n",
       "  0.01615826226770878,\n",
       "  -0.022277895361185074,\n",
       "  -0.010353576391935349,\n",
       "  0.004946443252265453,\n",
       "  -0.03557845950126648,\n",
       "  -0.03448758274316788,\n",
       "  -0.023384535685181618,\n",
       "  0.015269502066075802,\n",
       "  -0.017051735892891884,\n",
       "  0.002972567221149802,\n",
       "  0.010946904309093952,\n",
       "  0.009165854193270206,\n",
       "  -0.009988522157073021,\n",
       "  -0.014517105184495449,\n",
       "  -0.00454501761123538,\n",
       "  -0.01542951725423336,\n",
       "  0.05863422527909279,\n",
       "  0.0044991071335971355,\n",
       "  -0.009344669990241528,\n",
       "  -0.008313783444464207,\n",
       "  0.031020641326904297,\n",
       "  0.004981858190149069,\n",
       "  0.016493696719408035,\n",
       "  -0.016364512965083122,\n",
       "  0.004933882504701614,\n",
       "  -0.012700713239610195,\n",
       "  -0.011992894113063812,\n",
       "  -0.030063115060329437,\n",
       "  0.0025053289718925953,\n",
       "  -0.021027924492955208,\n",
       "  -0.009595970623195171,\n",
       "  -0.0020270643290132284,\n",
       "  0.012628672644495964,\n",
       "  -0.013141999952495098,\n",
       "  0.003797082230448723,\n",
       "  -0.024401215836405754,\n",
       "  0.0027585579082369804,\n",
       "  -0.015850583091378212,\n",
       "  0.021547652781009674,\n",
       "  0.030261412262916565,\n",
       "  -0.005235583055764437,\n",
       "  0.023011531680822372,\n",
       "  0.061019159853458405,\n",
       "  0.02206333912909031,\n",
       "  0.0047254119999706745,\n",
       "  -0.055226366966962814,\n",
       "  0.022738570347428322,\n",
       "  -0.016160039231181145,\n",
       "  0.023609111085534096,\n",
       "  -0.0017989801708608866,\n",
       "  0.006173392757773399,\n",
       "  0.008578821085393429,\n",
       "  -0.002966395579278469,\n",
       "  0.0028854315169155598,\n",
       "  -0.010022508911788464,\n",
       "  -0.020008264109492302,\n",
       "  0.012107493355870247,\n",
       "  0.03215160593390465,\n",
       "  0.015097481198608875,\n",
       "  -0.020575247704982758,\n",
       "  -0.003222670406103134,\n",
       "  0.008282453753054142,\n",
       "  0.011667247861623764,\n",
       "  0.0008133940282277763,\n",
       "  0.02407277375459671,\n",
       "  -0.017758747562766075,\n",
       "  0.012004406191408634,\n",
       "  -0.007819576188921928,\n",
       "  -0.026647938415408134,\n",
       "  0.011710559949278831,\n",
       "  -0.029195444658398628,\n",
       "  -0.034024231135845184,\n",
       "  -0.019091058522462845,\n",
       "  -0.009226644411683083,\n",
       "  0.01785152778029442,\n",
       "  -0.0056389798410236835,\n",
       "  -0.0271405391395092,\n",
       "  0.025725988671183586,\n",
       "  0.013031325303018093,\n",
       "  0.005302224308252335,\n",
       "  0.047211986035108566,\n",
       "  0.011385292746126652,\n",
       "  0.009558641351759434,\n",
       "  0.0018669459968805313,\n",
       "  -0.005533950868993998,\n",
       "  -0.006199168507009745,\n",
       "  -0.07183141261339188,\n",
       "  0.019795700907707214,\n",
       "  -0.0027279008645564318,\n",
       "  -0.02628934569656849,\n",
       "  0.014035038650035858,\n",
       "  0.0042381142266094685,\n",
       "  -0.03414158895611763,\n",
       "  -0.031962569802999496,\n",
       "  -0.015460973605513573,\n",
       "  0.015200505033135414,\n",
       "  0.0002332245057914406,\n",
       "  -0.020418021827936172,\n",
       "  0.03441961482167244,\n",
       "  -0.01436755433678627,\n",
       "  -0.0002996818220708519,\n",
       "  0.4235890805721283,\n",
       "  -0.014841660857200623,\n",
       "  -0.0029656318947672844,\n",
       "  0.0341433621942997,\n",
       "  0.028885073959827423,\n",
       "  -0.009351982735097408,\n",
       "  0.02233688347041607,\n",
       "  0.016227617859840393,\n",
       "  0.006928754970431328],\n",
       " 'label': 'AI13',\n",
       " 'file_path': 'dataset/lamp/AI13/20251112_104324.jpg'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_embeddings[30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f354731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Query image: dataset/lamp/AI13/20251112_104324.jpg (True label: AI13)\n",
      "Top 5 similar images from training set:\n",
      "1. AI13 - dataset/lamp/AI13/20251112_104323.jpg (Distance: 0.0080)\n",
      "2. AI13 - dataset/lamp/AI13/20251112_104322.jpg (Distance: 0.0155)\n",
      "3. AI13 - dataset/lamp/AI13/20251112_104321.jpg (Distance: 0.0338)\n",
      "4. AI13 - dataset/lamp/AI13/20251112_104319.jpg (Distance: 0.0343)\n",
      "5. AI13 - dataset/lamp/AI13/20251112_104328.jpg (Distance: 0.0373)\n",
      "‚úÖ Correct prediction!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('AI13', 'dataset/lamp/AI13/20251112_104323.jpg', 0.008027583121427373),\n",
       " ('AI13', 'dataset/lamp/AI13/20251112_104322.jpg', 0.0154971177727804),\n",
       " ('AI13', 'dataset/lamp/AI13/20251112_104321.jpg', 0.03381093832685356),\n",
       " ('AI13', 'dataset/lamp/AI13/20251112_104319.jpg', 0.034320562055090376),\n",
       " ('AI13', 'dataset/lamp/AI13/20251112_104328.jpg', 0.03726346633315569)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_single_validation_image(val_embedding=val_embeddings[0], connection=connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182ee32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Evaluate on a random validation image\n",
    "if val_embeddings:\n",
    "    import random\n",
    "    random_val_image = random.choice(val_embeddings)\n",
    "    print(\"üìù Example evaluation on a random validation image:\")\n",
    "    evaluate_single_validation_image(random_val_image, connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "25bddd59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Running full multi-class validation evaluation...\n",
      "üîç Evaluating model on 164 validation images...\n",
      "Progress: 10/164\n",
      "Progress: 20/164\n",
      "Progress: 30/164\n",
      "Progress: 40/164\n",
      "Progress: 50/164\n",
      "Progress: 60/164\n",
      "Progress: 70/164\n",
      "Progress: 80/164\n",
      "Progress: 90/164\n",
      "Progress: 100/164\n",
      "Progress: 110/164\n",
      "Progress: 120/164\n",
      "Progress: 130/164\n",
      "Progress: 140/164\n",
      "Progress: 150/164\n",
      "Progress: 160/164\n",
      "\n",
      "üìà Evaluation Results:\n",
      "Correct predictions: 164/164\n",
      "Accuracy: 100.00%\n",
      "\n",
      "üîç Calculating per-class accuracy...\n",
      "\n",
      "üéØ Final Multi-Class Evaluation Summary:\n",
      "Overall validation accuracy: 100.00%\n",
      "Overall correct predictions: 164/164\n",
      "\n",
      "üìä Per-Class Results:\n",
      "  AI12: 100.00% (19/19)\n",
      "  AI13: 100.00% (21/21)\n",
      "  AI17: 100.00% (21/21)\n",
      "  AI18: 100.00% (26/26)\n",
      "  AI6: 100.00% (21/21)\n",
      "  AI7: 100.00% (23/23)\n",
      "  AI9: 100.00% (33/33)\n",
      "\n",
      "üèÜ Performance Assessment:\n",
      "üèÜ Excellent overall performance!\n",
      "\n",
      "üìà Class Performance:\n",
      "Best performing: AI6 (100.00%)\n",
      "Worst performing: AI6 (100.00%)\n",
      "\n",
      "üîÑ Classes to investigate:\n"
     ]
    }
   ],
   "source": [
    "# Run full evaluation on multi-class validation set\n",
    "if val_embeddings:\n",
    "    print(\"üöÄ Running full multi-class validation evaluation...\")\n",
    "    accuracy, correct, total = evaluate_model_on_validation(val_embeddings, connection, top_k=5)\n",
    "    \n",
    "    # Calculate per-class accuracy\n",
    "    class_correct = {}\n",
    "    class_total = {}\n",
    "    class_accuracy = {}\n",
    "    \n",
    "    print(f\"\\nüîç Calculating per-class accuracy...\")\n",
    "    \n",
    "    for val_embedding in val_embeddings:\n",
    "        query_embedding = val_embedding[\"embedding\"]\n",
    "        true_label = val_embedding[\"label\"]\n",
    "        \n",
    "        # Initialize counters\n",
    "        if true_label not in class_total:\n",
    "            class_total[true_label] = 0\n",
    "            class_correct[true_label] = 0\n",
    "        \n",
    "        class_total[true_label] += 1\n",
    "        \n",
    "        # Search in the database\n",
    "        cur = connection.cursor()\n",
    "        sql = \"\"\"\n",
    "        SELECT class_name, path, \n",
    "               vec_cosine_distance(image_embedding, %s) AS distance\n",
    "        FROM equipment_embeddings\n",
    "        ORDER BY distance ASC\n",
    "        LIMIT 1;\n",
    "        \"\"\"\n",
    "        cur.execute(sql, (json.dumps(query_embedding),))\n",
    "        result = cur.fetchone()\n",
    "        cur.close()\n",
    "        \n",
    "        if result and result[0] == true_label:\n",
    "            class_correct[true_label] += 1\n",
    "    \n",
    "    # Calculate per-class accuracy\n",
    "    for class_name in class_total:\n",
    "        class_accuracy[class_name] = (class_correct[class_name] / class_total[class_name]) * 100\n",
    "    \n",
    "    print(f\"\\nüéØ Final Multi-Class Evaluation Summary:\")\n",
    "    print(f\"Overall validation accuracy: {accuracy:.2f}%\")\n",
    "    print(f\"Overall correct predictions: {correct}/{total}\")\n",
    "    \n",
    "    print(f\"\\nüìä Per-Class Results:\")\n",
    "    for class_name in sorted(class_accuracy.keys()):\n",
    "        acc = class_accuracy[class_name]\n",
    "        print(f\"  {class_name}: {acc:.2f}% ({class_correct[class_name]}/{class_total[class_name]})\")\n",
    "    \n",
    "    # Overall performance assessment\n",
    "    print(f\"\\nüèÜ Performance Assessment:\")\n",
    "    if accuracy >= 90:\n",
    "        print(\"üèÜ Excellent overall performance!\")\n",
    "    elif accuracy >= 70:\n",
    "        print(\"üëç Good overall performance!\")\n",
    "    elif accuracy >= 50:\n",
    "        print(\"‚ö†Ô∏è Average performance - consider model improvements\")\n",
    "    else:\n",
    "        print(\"üî¥ Poor performance - needs significant improvement\")\n",
    "    \n",
    "    # Find best and worst performing classes\n",
    "    if class_accuracy:\n",
    "        best_class = max(class_accuracy, key=class_accuracy.get)\n",
    "        worst_class = min(class_accuracy, key=class_accuracy.get)\n",
    "        \n",
    "        print(f\"\\nüìà Class Performance:\")\n",
    "        print(f\"Best performing: {best_class} ({class_accuracy[best_class]:.2f}%)\")\n",
    "        print(f\"Worst performing: {worst_class} ({class_accuracy[worst_class]:.2f}%)\")\n",
    "        \n",
    "        # Show which classes might be confused\n",
    "        print(f\"\\nüîÑ Classes to investigate:\")\n",
    "        for class_name, acc in class_accuracy.items():\n",
    "            if acc < 80:\n",
    "                print(f\"  {class_name}: {acc:.2f}% - may need more training data or better features\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå No validation embeddings available for evaluation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8f8145",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
