{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7940b1e5-15c7-4d1d-826f-bb66d1fd4c94",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.9.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.24.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (5.9 kB)\n",
      "Collecting torchaudio\n",
      "  Downloading torchaudio-2.9.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.15.0)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /opt/conda/lib/python3.10/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /opt/conda/lib/python3.10/site-packages (from torch) (2025.10.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch)\n",
      "  Downloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch)\n",
      "  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch)\n",
      "  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.9.90 (from torch)\n",
      "  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch)\n",
      "  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch)\n",
      "  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.7.1 (from torch)\n",
      "  Downloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
      "Collecting nvidia-nccl-cu12==2.27.5 (from torch)\n",
      "  Downloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting nvidia-nvshmem-cu12==3.3.20 (from torch)\n",
      "  Downloading nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.8.90 (from torch)\n",
      "  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch)\n",
      "  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==3.5.1 (from torch)\n",
      "  Downloading triton-3.5.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision) (12.0.0)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (3.0.3)\n",
      "Downloading torch-2.9.1-cp310-cp310-manylinux_2_28_x86_64.whl (899.8 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m899.8/899.8 MB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m  \u001b[33m0:00:12\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m  \u001b[33m0:00:08\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m6m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m104.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m706.8/706.8 MB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m  \u001b[33m0:00:10\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m97.4 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m82.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m104.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m99.3 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m65.4 MB/s\u001b[0m  \u001b[33m0:00:04\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m287.2/287.2 MB\u001b[0m \u001b[31m91.1 MB/s\u001b[0m  \u001b[33m0:00:03\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.3 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m322.3/322.3 MB\u001b[0m \u001b[31m59.4 MB/s\u001b[0m  \u001b[33m0:00:04\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m6m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (124.7 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m124.7/124.7 MB\u001b[0m \u001b[31m101.5 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "Downloading triton-3.5.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (170.3 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m170.3/170.3 MB\u001b[0m \u001b[31m96.6 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchvision-0.24.1-cp310-cp310-manylinux_2_28_x86_64.whl (8.0 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m108.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torchaudio-2.9.1-cp310-cp310-manylinux_2_28_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m107.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m152.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-cusparselt-cu12, mpmath, triton, sympy, nvidia-nvtx-cu12, nvidia-nvshmem-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision, torchaudio\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m21/21\u001b[0m [torchaudio]1\u001b[0m [torchaudio]]ver-cu12]2]2]\n",
      "\u001b[1A\u001b[2KSuccessfully installed mpmath-1.3.0 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-cusparselt-cu12-0.7.1 nvidia-nccl-cu12-2.27.5 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvshmem-cu12-3.3.20 nvidia-nvtx-cu12-12.8.90 sympy-1.14.0 torch-2.9.1 torchaudio-2.9.1 torchvision-0.24.1 triton-3.5.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision torchaudio transformers sentencepiece gcsfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "932a2a6e-b9e8-4447-a56b-30ff81ecfca5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-11T07:10:09.826156Z",
     "iopub.status.busy": "2025-12-11T07:10:09.825793Z",
     "iopub.status.idle": "2025-12-11T07:10:23.028875Z",
     "shell.execute_reply": "2025-12-11T07:10:23.028126Z",
     "shell.execute_reply.started": "2025-12-11T07:10:09.826125Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import AutoProcessor, AutoModel\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud import aiplatform_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b468a10-ab7b-4080-9bfa-d49907741af9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-11T07:24:24.679312Z",
     "iopub.status.busy": "2025-12-11T07:24:24.678942Z",
     "iopub.status.idle": "2025-12-11T07:24:24.683986Z",
     "shell.execute_reply": "2025-12-11T07:24:24.682846Z",
     "shell.execute_reply.started": "2025-12-11T07:24:24.679285Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"629242692180\"  \n",
    "REGION = \"asia-southeast1\"     \n",
    "\n",
    "# Set variables for the current deployed index.\n",
    "API_ENDPOINT=\"1148065613.asia-southeast1-629242692180.vdb.vertexai.goog\"\n",
    "INDEX_ENDPOINT=\"projects/629242692180/locations/asia-southeast1/indexEndpoints/43567048738996224\"\n",
    "DEPLOYED_INDEX_ID=\"equipment_profile_1765274237629\"\n",
    "QUERY_IMAGE_PATH = \"datatest/AI2/20251112_111947(0).jpg\"\n",
    "NUM_NEIGHBORS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bed3db2f-4831-4ea2-bbfe-e62abda838cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-11T07:23:45.010997Z",
     "iopub.status.busy": "2025-12-11T07:23:45.010034Z",
     "iopub.status.idle": "2025-12-11T07:23:45.020391Z",
     "shell.execute_reply": "2025-12-11T07:23:45.019645Z",
     "shell.execute_reply.started": "2025-12-11T07:23:45.010963Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "client_options = {\n",
    "  \"api_endpoint\": API_ENDPOINT\n",
    "}\n",
    "vector_search_client = aiplatform_v1.MatchServiceClient(\n",
    "  client_options=client_options,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3941c1f-5667-4d3c-b6ef-d083e5fdde3a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-11T07:23:46.421388Z",
     "iopub.status.busy": "2025-12-11T07:23:46.421039Z",
     "iopub.status.idle": "2025-12-11T07:23:50.430981Z",
     "shell.execute_reply": "2025-12-11T07:23:50.429747Z",
     "shell.execute_reply.started": "2025-12-11T07:23:46.421358Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SigLIP model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    processor = AutoProcessor.from_pretrained(\"google/siglip-base-patch16-224\")\n",
    "    model = AutoModel.from_pretrained(\"google/siglip-base-patch16-224\")\n",
    "    model.eval()\n",
    "    print(\"SigLIP model loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading SigLIP model: {e}\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9929ab2-128d-4e8f-b9bc-5357e51141bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-11T07:23:50.432788Z",
     "iopub.status.busy": "2025-12-11T07:23:50.432512Z",
     "iopub.status.idle": "2025-12-11T07:23:50.438745Z",
     "shell.execute_reply": "2025-12-11T07:23:50.437624Z",
     "shell.execute_reply.started": "2025-12-11T07:23:50.432761Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_query_embedding(image_path: str) -> list:\n",
    "    if not os.path.exists(image_path):\n",
    "        raise FileNotFoundError(f\"Query image not found at: {image_path}\")\n",
    "\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    \n",
    "    # Pre-processing\n",
    "    inputs = processor(images=image, return_tensors=\"pt\")\n",
    "    \n",
    "    # Inference\n",
    "    with torch.no_grad():\n",
    "        outputs = model.get_image_features(**inputs)\n",
    "        query_vector = outputs / outputs.norm(p=2, dim=-1, keepdim=True)\n",
    "    \n",
    "    return query_vector.squeeze(0).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7611c3f8-a8c5-4bf7-bcde-69158b26994d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-11T07:24:26.882666Z",
     "iopub.status.busy": "2025-12-11T07:24:26.882005Z",
     "iopub.status.idle": "2025-12-11T07:24:26.888922Z",
     "shell.execute_reply": "2025-12-11T07:24:26.887849Z",
     "shell.execute_reply.started": "2025-12-11T07:24:26.882629Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def vector_search(query_image_path: str, index_endpoint: str, deploy_index_id: str, num_neighbors: int):\n",
    "    try:\n",
    "        query_embedding_vector = create_query_embedding(query_image_path)\n",
    "        \n",
    "        datapoint = aiplatform_v1.IndexDatapoint(\n",
    "          feature_vector=query_embedding_vector\n",
    "        )\n",
    "\n",
    "        query = aiplatform_v1.FindNeighborsRequest.Query(\n",
    "          datapoint=datapoint,\n",
    "\n",
    "          # The number of nearest neighbors to be retrieved\n",
    "          neighbor_count=num_neighbors\n",
    "        )\n",
    "\n",
    "        # filter_condition = [\n",
    "        #     {\"namespace\": \"metadata.label_class\", \"allow_list\": [\"AI1\"]} # use namespace 'metadata.label_class'\n",
    "        # ]\n",
    "        filter_condition = None\n",
    "        \n",
    "        try:\n",
    "            request = aiplatform_v1.FindNeighborsRequest(\n",
    "              index_endpoint=index_endpoint,\n",
    "              deployed_index_id=deploy_index_id,\n",
    "              # Request can have multiple queries\n",
    "              queries=[query],\n",
    "              return_full_datapoint=False,\n",
    "            )\n",
    "\n",
    "            # Execute the request\n",
    "            response = vector_search_client.find_neighbors(request)\n",
    "            \n",
    "            # Handle the response\n",
    "            return response\n",
    "        except Exception as e:\n",
    "            print(f\"ERROR: {e}\")\n",
    "            return\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error creating embedding: {e}\")\n",
    "        return\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9418f5e8-dde1-4ef3-8020-55d9361873d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-11T07:24:33.834367Z",
     "iopub.status.busy": "2025-12-11T07:24:33.834041Z",
     "iopub.status.idle": "2025-12-11T07:24:34.366463Z",
     "shell.execute_reply": "2025-12-11T07:24:34.364867Z",
     "shell.execute_reply.started": "2025-12-11T07:24:33.834341Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nearest_neighbors {\n",
       "  neighbors {\n",
       "    datapoint {\n",
       "      datapoint_id: \"equipment_train_AI2_20251112_111948.jpg\"\n",
       "      crowding_tag {\n",
       "        crowding_attribute: \"0\"\n",
       "      }\n",
       "    }\n",
       "    distance: 0.96325886249542236\n",
       "  }\n",
       "  neighbors {\n",
       "    datapoint {\n",
       "      datapoint_id: \"equipment_train_AI2_20251112_111948(0).jpg\"\n",
       "      crowding_tag {\n",
       "        crowding_attribute: \"0\"\n",
       "      }\n",
       "    }\n",
       "    distance: 0.9466739296913147\n",
       "  }\n",
       "  neighbors {\n",
       "    datapoint {\n",
       "      datapoint_id: \"equipment_train_AI2_20251112_111943(0).jpg\"\n",
       "      crowding_tag {\n",
       "        crowding_attribute: \"0\"\n",
       "      }\n",
       "    }\n",
       "    distance: 0.94594419002532959\n",
       "  }\n",
       "  neighbors {\n",
       "    datapoint {\n",
       "      datapoint_id: \"equipment_train_AI2_20251112_111947.jpg\"\n",
       "      crowding_tag {\n",
       "        crowding_attribute: \"0\"\n",
       "      }\n",
       "    }\n",
       "    distance: 0.93916523456573486\n",
       "  }\n",
       "  neighbors {\n",
       "    datapoint {\n",
       "      datapoint_id: \"equipment_train_AI2_20251112_111949.jpg\"\n",
       "      crowding_tag {\n",
       "        crowding_attribute: \"0\"\n",
       "      }\n",
       "    }\n",
       "    distance: 0.93807220458984375\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = vector_search(QUERY_IMAGE_PATH, INDEX_ENDPOINT, DEPLOYED_INDEX_ID, NUM_NEIGHBORS)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a5b2d5d7-0748-48b5-bab4-f036fba9d042",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-11T07:57:50.950695Z",
     "iopub.status.busy": "2025-12-11T07:57:50.950292Z",
     "iopub.status.idle": "2025-12-11T07:57:50.956371Z",
     "shell.execute_reply": "2025-12-11T07:57:50.955313Z",
     "shell.execute_reply.started": "2025-12-11T07:57:50.950663Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datapoint {\n",
      "  datapoint_id: \"equipment_train_AI2_20251112_111948.jpg\"\n",
      "  crowding_tag {\n",
      "    crowding_attribute: \"0\"\n",
      "  }\n",
      "}\n",
      "distance: 0.96325886249542236\n",
      "\n"
     ]
    }
   ],
   "source": [
    "first_query_result = res.nearest_neighbors[0]\n",
    "neighbors = first_query_result.neighbors\n",
    "neighbor = neighbors[0]\n",
    "print(neighbor) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "abc7e182-59dd-4431-b594-15ace79e67de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-11T07:58:01.415599Z",
     "iopub.status.busy": "2025-12-11T07:58:01.414962Z",
     "iopub.status.idle": "2025-12-11T07:58:01.668790Z",
     "shell.execute_reply": "2025-12-11T07:58:01.668028Z",
     "shell.execute_reply.started": "2025-12-11T07:58:01.415566Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "import json\n",
    "\n",
    "client = storage.Client()\n",
    "bucket = client.bucket(\"axmt_equipment_profile\")\n",
    "blob = bucket.blob(\"siglip_vectors/local_image_vectors.json\")\n",
    "\n",
    "content = blob.download_as_text()\n",
    "\n",
    "original_path = {}\n",
    "label_class = {}\n",
    "\n",
    "for l in content.splitlines():\n",
    "    p = json.loads(l)\n",
    "    id = p['id']\n",
    "    original_path[id] = p['original_path']\n",
    "    label_class[id] = p['label_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a8d0fc-2c62-4d26-89b9-dc01c50b6911",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9900587",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_equipment_test_dataset_from_embeddings(test_data_path=\"gs://axmt_equipment_profile/siglip_vectors\",\n",
    "                                                     index_endpoint=INDEX_ENDPOINT, \n",
    "                                                     deployed_index_id=DEPLOYED_INDEX_ID, \n",
    "                                                     num_neighbors=5,\n",
    "                                                     max_images_per_class=None):\n",
    "    \"\"\"\n",
    "    Evaluate the vector search system using pre-computed embeddings from JSON files in GCS.\n",
    "    This function uses embeddings directly instead of processing raw images.\n",
    "    \n",
    "    Args:\n",
    "        test_data_path (str): Path to GCS bucket containing JSON files with embeddings\n",
    "        index_endpoint (str): Vector search index endpoint\n",
    "        deployed_index_id (str): Deployed index ID\n",
    "        num_neighbors (int): Number of neighbors to retrieve\n",
    "        max_images_per_class (int): Maximum number of images to test per class (None for all)\n",
    "    \n",
    "    Returns:\n",
    "        dict: Evaluation results including accuracy metrics\n",
    "    \"\"\"\n",
    "    from collections import defaultdict\n",
    "    import time\n",
    "    import json\n",
    "    from google.cloud import storage\n",
    "    from google.cloud import aiplatform_v1\n",
    "    \n",
    "    # Initialize results tracking\n",
    "    results = {\n",
    "        'total_queries': 0,\n",
    "        'correct_predictions': 0,\n",
    "        'class_results': defaultdict(lambda: {'total': 0, 'correct': 0, 'predictions': []}),\n",
    "        'detailed_results': []\n",
    "    }\n",
    "    \n",
    "    # Load test embeddings from GCS\n",
    "    test_embeddings = []\n",
    "    \n",
    "    print(f\"Loading test embeddings from GCS path: {test_data_path}\")\n",
    "    \n",
    "    # Parse GCS path\n",
    "    gcs_path = test_data_path.replace('gs://', '')\n",
    "    bucket_name = gcs_path.split('/')[0]\n",
    "    blob_prefix = '/'.join(gcs_path.split('/')[1:]) if len(gcs_path.split('/')) > 1 else ''\n",
    "    \n",
    "    # Initialize GCS client\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    \n",
    "    # List all JSON files in the GCS path\n",
    "    blobs = bucket.list_blobs(prefix=blob_prefix)\n",
    "    \n",
    "    for blob in blobs:\n",
    "        if blob.name.endswith('.json'):\n",
    "            print(f\"Processing GCS file: {blob.name}\")\n",
    "            \n",
    "            try:\n",
    "                # Download and parse JSON content\n",
    "                content = blob.download_as_text()\n",
    "                \n",
    "                for line in content.splitlines():\n",
    "                    if line.strip():\n",
    "                        try:\n",
    "                            embedding_data = json.loads(line)\n",
    "                            \n",
    "                            # Extract relevant information\n",
    "                            original_path = embedding_data.get('original_path', '')\n",
    "                            label_class_val = embedding_data.get('label_class', '')\n",
    "                            embedding_vector = embedding_data.get('embedding', [])\n",
    "                            data_id = embedding_data.get('id', '')\n",
    "                            \n",
    "                            # Filter for test images (assuming they contain 'test' in path)\n",
    "                            if 'test' in original_path.lower() and embedding_vector:\n",
    "                                test_embeddings.append({\n",
    "                                    'path': original_path,\n",
    "                                    'class': label_class_val,\n",
    "                                    'id': data_id,\n",
    "                                    'embedding': embedding_vector\n",
    "                                })\n",
    "                                \n",
    "                        except json.JSONDecodeError as e:\n",
    "                            print(f\"Error parsing JSON line: {e}\")\n",
    "                            continue\n",
    "                            \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing GCS blob {blob.name}: {e}\")\n",
    "                continue\n",
    "    \n",
    "    if not test_embeddings:\n",
    "        raise ValueError(\"No test embeddings found. Please check your GCS path contains test data.\")\n",
    "    \n",
    "    print(f\"Found {len(test_embeddings)} test embeddings from GCS\")\n",
    "    \n",
    "    # Group by class for max_images_per_class filtering\n",
    "    embeddings_by_class = defaultdict(list)\n",
    "    for emb_data in test_embeddings:\n",
    "        embeddings_by_class[emb_data['class']].append(emb_data)\n",
    "    \n",
    "    # Apply max_images_per_class limit if specified\n",
    "    if max_images_per_class:\n",
    "        filtered_embeddings = []\n",
    "        for class_name, class_embeddings in embeddings_by_class.items():\n",
    "            filtered_embeddings.extend(class_embeddings[:max_images_per_class])\n",
    "        test_embeddings = filtered_embeddings\n",
    "    \n",
    "    # Get unique classes\n",
    "    equipment_classes = list(set([emb['class'] for emb in test_embeddings]))\n",
    "    \n",
    "    print(f\"Found {len(equipment_classes)} equipment classes: {sorted(equipment_classes)}\")\n",
    "    print(f\"Total test embeddings: {len(test_embeddings)}\")\n",
    "    print(f\"Starting evaluation with {num_neighbors} neighbors per query...\\n\")\n",
    "    \n",
    "    # Process each test embedding\n",
    "    for emb_data in test_embeddings:\n",
    "        original_path = emb_data['path']\n",
    "        true_class = emb_data['class']\n",
    "        query_embedding = emb_data['embedding']\n",
    "        \n",
    "        try:\n",
    "            # Create vector search request using pre-computed embedding\n",
    "            datapoint = aiplatform_v1.IndexDatapoint(\n",
    "                feature_vector=query_embedding\n",
    "            )\n",
    "\n",
    "            query = aiplatform_v1.FindNeighborsRequest.Query(\n",
    "                datapoint=datapoint,\n",
    "                neighbor_count=num_neighbors\n",
    "            )\n",
    "\n",
    "            request = aiplatform_v1.FindNeighborsRequest(\n",
    "                index_endpoint=index_endpoint,\n",
    "                deployed_index_id=deployed_index_id,\n",
    "                queries=[query],\n",
    "                return_full_datapoint=False,\n",
    "            )\n",
    "\n",
    "            # Execute the request\n",
    "            response = vector_search_client.find_neighbors(request)\n",
    "            \n",
    "            if response and response.nearest_neighbors:\n",
    "                # Get the top prediction\n",
    "                neighbors = response.nearest_neighbors[0].neighbors\n",
    "                \n",
    "                # Extract predicted classes from neighbors\n",
    "                predicted_classes = []\n",
    "                neighbor_details = []\n",
    "                \n",
    "                for neighbor in neighbors:\n",
    "                    neighbor_id = neighbor.datapoint.datapoint_id\n",
    "                    distance = neighbor.distance\n",
    "                    \n",
    "                    # Get the predicted class from the neighbor ID\n",
    "                    if neighbor_id in label_class:\n",
    "                        pred_class = label_class[neighbor_id]\n",
    "                        predicted_classes.append(pred_class)\n",
    "                        \n",
    "                        neighbor_details.append({\n",
    "                            'id': neighbor_id,\n",
    "                            'predicted_class': pred_class,\n",
    "                            'distance': distance,\n",
    "                            'original_path': original_path.get(neighbor_id, 'Unknown')\n",
    "                        })\n",
    "                \n",
    "                # Determine if prediction is correct (top-1 and top-k accuracy)\n",
    "                top1_correct = predicted_classes[0] == true_class if predicted_classes else False\n",
    "                topk_correct = true_class in predicted_classes[:num_neighbors] if predicted_classes else False\n",
    "                \n",
    "                # Update results\n",
    "                results['total_queries'] += 1\n",
    "                results['class_results'][true_class]['total'] += 1\n",
    "                \n",
    "                if top1_correct:\n",
    "                    results['correct_predictions'] += 1\n",
    "                    results['class_results'][true_class]['correct'] += 1\n",
    "                \n",
    "                # Store detailed results\n",
    "                result_detail = {\n",
    "                    'query_image': original_path,\n",
    "                    'true_class': true_class,\n",
    "                    'predicted_classes': predicted_classes,\n",
    "                    'top1_correct': top1_correct,\n",
    "                    'topk_correct': topk_correct,\n",
    "                    'neighbors': neighbor_details\n",
    "                }\n",
    "                results['detailed_results'].append(result_detail)\n",
    "                results['class_results'][true_class]['predictions'].append(result_detail)\n",
    "                \n",
    "                # Print progress\n",
    "                if results['total_queries'] % 10 == 0:\n",
    "                    current_accuracy = (results['correct_predictions'] / results['total_queries']) * 100\n",
    "                    print(f\"Processed {results['total_queries']} embeddings, Current accuracy: {current_accuracy:.2f}%\")\n",
    "            \n",
    "            else:\n",
    "                print(f\"No response for embedding: {original_path}\")\n",
    "                \n",
    "            # Small delay to avoid overwhelming the API\n",
    "            time.sleep(0.1)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing embedding {original_path}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Calculate final metrics\n",
    "    overall_accuracy = (results['correct_predictions'] / results['total_queries']) * 100 if results['total_queries'] > 0 else 0\n",
    "    \n",
    "    # Calculate per-class accuracy\n",
    "    class_accuracies = {}\n",
    "    for class_name, class_data in results['class_results'].items():\n",
    "        if class_data['total'] > 0:\n",
    "            class_accuracies[class_name] = (class_data['correct'] / class_data['total']) * 100\n",
    "        else:\n",
    "            class_accuracies[class_name] = 0\n",
    "    \n",
    "    # Add summary to results\n",
    "    results['summary'] = {\n",
    "        'overall_accuracy': overall_accuracy,\n",
    "        'class_accuracies': class_accuracies,\n",
    "        'total_classes': len(equipment_classes),\n",
    "        'avg_class_accuracy': sum(class_accuracies.values()) / len(class_accuracies) if class_accuracies else 0\n",
    "    }\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25380e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_evaluation_results(results):\n",
    "    \"\"\"\n",
    "    Display comprehensive evaluation results in a formatted way.\n",
    "    \n",
    "    Args:\n",
    "        results (dict): Results from evaluate_equipment_test_dataset function\n",
    "    \"\"\"\n",
    "    print(\"=\" * 80)\n",
    "    print(\"EQUIPMENT PROFILE VECTOR SEARCH EVALUATION RESULTS\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Overall summary\n",
    "    summary = results['summary']\n",
    "    print(f\"\\nüìä OVERALL PERFORMANCE:\")\n",
    "    print(f\"   Total Queries: {results['total_queries']}\")\n",
    "    print(f\"   Correct Predictions: {results['correct_predictions']}\")\n",
    "    print(f\"   Overall Accuracy: {summary['overall_accuracy']:.2f}%\")\n",
    "    print(f\"   Average Class Accuracy: {summary['avg_class_accuracy']:.2f}%\")\n",
    "    print(f\"   Total Classes: {summary['total_classes']}\")\n",
    "    \n",
    "    # Per-class results\n",
    "    print(f\"\\nüìã PER-CLASS ACCURACY:\")\n",
    "    class_results = results['class_results']\n",
    "    class_accuracies = summary['class_accuracies']\n",
    "    \n",
    "    # Sort by accuracy for better visualization\n",
    "    sorted_classes = sorted(class_accuracies.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    print(f\"{'Class':<8} {'Accuracy':<10} {'Correct/Total':<15} {'Status'}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for class_name, accuracy in sorted_classes:\n",
    "        total = class_results[class_name]['total']\n",
    "        correct = class_results[class_name]['correct']\n",
    "        status = \"‚úÖ Excellent\" if accuracy >= 90 else \"‚ö†Ô∏è Good\" if accuracy >= 70 else \"‚ùå Needs Work\"\n",
    "        print(f\"{class_name:<8} {accuracy:<10.2f}% {correct}/{total:<13} {status}\")\n",
    "    \n",
    "    # Confusion analysis\n",
    "    print(f\"\\nüîç CONFUSION ANALYSIS:\")\n",
    "    confusion_data = defaultdict(lambda: defaultdict(int))\n",
    "    \n",
    "    for detail in results['detailed_results']:\n",
    "        true_class = detail['true_class']\n",
    "        if detail['predicted_classes']:\n",
    "            pred_class = detail['predicted_classes'][0]  # Top prediction\n",
    "            confusion_data[true_class][pred_class] += 1\n",
    "    \n",
    "    # Show most common misclassifications\n",
    "    print(\"Most common misclassifications:\")\n",
    "    misclassifications = []\n",
    "    for true_class, predictions in confusion_data.items():\n",
    "        for pred_class, count in predictions.items():\n",
    "            if true_class != pred_class and count > 0:\n",
    "                misclassifications.append((true_class, pred_class, count))\n",
    "    \n",
    "    # Sort by frequency\n",
    "    misclassifications.sort(key=lambda x: x[2], reverse=True)\n",
    "    \n",
    "    if misclassifications:\n",
    "        print(f\"{'True Class':<10} {'Predicted As':<12} {'Count'}\")\n",
    "        print(\"-\" * 35)\n",
    "        for true_cls, pred_cls, count in misclassifications[:10]:  # Top 10 misclassifications\n",
    "            print(f\"{true_cls:<10} {pred_cls:<12} {count}\")\n",
    "    else:\n",
    "        print(\"No misclassifications found!\")\n",
    "    \n",
    "    # Performance insights\n",
    "    print(f\"\\nüí° INSIGHTS:\")\n",
    "    best_class = max(class_accuracies.items(), key=lambda x: x[1])\n",
    "    worst_class = min(class_accuracies.items(), key=lambda x: x[1])\n",
    "    \n",
    "    print(f\"   Best performing class: {best_class[0]} ({best_class[1]:.2f}%)\")\n",
    "    print(f\"   Worst performing class: {worst_class[0]} ({worst_class[1]:.2f}%)\")\n",
    "    \n",
    "    accuracy_range = best_class[1] - worst_class[1]\n",
    "    print(f\"   Performance variance: {accuracy_range:.2f}%\")\n",
    "    \n",
    "    if accuracy_range > 30:\n",
    "        print(\"   ‚ö†Ô∏è High variance detected - some classes may need more training data\")\n",
    "    elif summary['overall_accuracy'] < 80:\n",
    "        print(\"   ‚ö†Ô∏è Overall accuracy below 80% - consider model fine-tuning\")\n",
    "    else:\n",
    "        print(\"   ‚úÖ Good performance consistency across classes\")\n",
    "\n",
    "def analyze_failed_predictions(results, class_name=None, top_n=5):\n",
    "    \"\"\"\n",
    "    Analyze failed predictions for debugging purposes.\n",
    "    \n",
    "    Args:\n",
    "        results (dict): Results from evaluate_equipment_test_dataset function\n",
    "        class_name (str): Specific class to analyze (None for all classes)\n",
    "        top_n (int): Number of failed cases to show\n",
    "    \"\"\"\n",
    "    print(f\"\\nüîç ANALYZING FAILED PREDICTIONS:\")\n",
    "    \n",
    "    failed_predictions = []\n",
    "    for detail in results['detailed_results']:\n",
    "        if not detail['top1_correct']:\n",
    "            if class_name is None or detail['true_class'] == class_name:\n",
    "                failed_predictions.append(detail)\n",
    "    \n",
    "    if not failed_predictions:\n",
    "        print(\"No failed predictions found!\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Found {len(failed_predictions)} failed predictions\")\n",
    "    if class_name:\n",
    "        print(f\"Filtering by class: {class_name}\")\n",
    "    \n",
    "    print(f\"\\nTop {min(top_n, len(failed_predictions))} failed cases:\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for i, failure in enumerate(failed_predictions[:top_n]):\n",
    "        print(f\"\\n{i+1}. Query: {failure['query_image']}\")\n",
    "        print(f\"   True class: {failure['true_class']}\")\n",
    "        print(f\"   Predicted: {failure['predicted_classes'][0] if failure['predicted_classes'] else 'No prediction'}\")\n",
    "        print(f\"   Top predictions: {failure['predicted_classes'][:3]}\")\n",
    "        \n",
    "        if failure['neighbors']:\n",
    "            print(f\"   Closest match distance: {failure['neighbors'][0]['distance']:.4f}\")\n",
    "            print(f\"   Closest match path: {failure['neighbors'][0]['original_path']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903f7d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage of evaluation functions with pre-computed embeddings from GCS\n",
    "\n",
    "# Use pre-computed embeddings directly from GCS (much faster!)\n",
    "print(\"Running evaluation using pre-computed embeddings from GCS (max 3 images per class)...\")\n",
    "quick_results = evaluate_equipment_test_dataset_from_embeddings(\n",
    "    test_data_path=\"gs://axmt_equipment_profile/siglip_vectors\",  # GCS path with embedding JSON files\n",
    "    index_endpoint=INDEX_ENDPOINT,\n",
    "    deployed_index_id=DEPLOYED_INDEX_ID,\n",
    "    num_neighbors=5,\n",
    "    max_images_per_class=3  # Limit for quick testing\n",
    ")\n",
    "\n",
    "# Display results\n",
    "display_evaluation_results(quick_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41ad512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full evaluation using pre-computed embeddings from GCS (uncomment to run complete evaluation)\n",
    "# WARNING: This may take a long time depending on the dataset size\n",
    "\n",
    "\"\"\"\n",
    "# Run full evaluation using pre-computed embeddings from GCS\n",
    "print(\"Running full evaluation using pre-computed embeddings from GCS...\")\n",
    "full_results = evaluate_equipment_test_dataset_from_embeddings(\n",
    "    test_data_path=\"gs://axmt_equipment_profile/siglip_vectors\",  # GCS path with embedding JSON files\n",
    "    index_endpoint=INDEX_ENDPOINT,\n",
    "    deployed_index_id=DEPLOYED_INDEX_ID,\n",
    "    num_neighbors=5,\n",
    "    max_images_per_class=None  # No limit - use all test embeddings\n",
    ")\n",
    "\n",
    "# Display comprehensive results\n",
    "display_evaluation_results(full_results)\n",
    "\n",
    "# Analyze failed predictions for specific classes\n",
    "analyze_failed_predictions(full_results, class_name=\"AI1\", top_n=5)\n",
    "analyze_failed_predictions(full_results, class_name=\"AI2\", top_n=5)\n",
    "\n",
    "# Save results to file for later analysis\n",
    "import json\n",
    "with open('evaluation_results_embeddings.json', 'w') as f:\n",
    "    # Convert defaultdict to regular dict for JSON serialization\n",
    "    results_copy = dict(full_results)\n",
    "    results_copy['class_results'] = dict(results_copy['class_results'])\n",
    "    json.dump(results_copy, f, indent=2, default=str)\n",
    "    \n",
    "print(\"Results saved to evaluation_results_embeddings.json\")\n",
    "\"\"\"\n",
    "\n",
    "print(\"Full evaluation code is commented out. Uncomment to run complete evaluation.\")\n",
    "print(\"Now uses pre-computed embeddings from GCS for much faster evaluation!\")"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m136",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m136"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
